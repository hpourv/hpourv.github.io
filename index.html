<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Mohammad Hoseinpour's homepage</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Mohammad.Hoseinpour" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="style.css" />
  <link rel="canonical" href="https://leonidk.com/">

  <LINK REL="SHORTCUT ICON" HREF="favicon.ico">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p align="center">
                <name>Mohammad Hoseinpour</name> <br>
                m.hoseinpour.v@gmail.com
              </p>
              <p>
               I am a final year M.Sc. student in Electrical Engineering in the Department of Electrical and Computer Engineering at Babol Noshirvani University of Technology, under the supervision of <a href="https://scholar.google.com/citations?hl=en&user=z-LNMvsAAAAJ&view_op=list_works&sortby=pubdate"> Prof. Ali Aghagolzadeh</a>. 
                <!-- My research current interests focus on scalable, automated and scalable machine learning. -->
              </p>
              <p>
                <!-- My research interests focus on <b>automated</b>, <b>scalable</b> and <b>efficient</b> machine learning. -->
                <p>My research interests broadly lie in probabilistic machine learning, generative modeling, information theory, and Stochastic Processes. Currently, my research  focuses on diffusion models, and their application  for solving inverse problems.</p>
              </p>
              <p>
                If you find any research interests that we might share, feel free to drop me an email. I am always open
                to potential collaborations.
                <!-- <del><font color="red"><strong>I am applying for Ph.D. positions.</strong></font> My research keyword
                includes: <i>Design Automation, Efficient & Scalable Machine Learning, Machine Learning Systems</i>.
                Feel free to drop me an email if you are interested.</del> -->
              </p>
              <p align="center">
                <a href="https://scholar.google.com/citations?user=SGy0Gj4AAAAJ&hl=en">Google Scholar</a>
                &nbsp;/&nbsp; <a href="CV.pdf">CV</a>
                <!-- &nbsp;/&nbsp; <a href="https://www.linkedin.com/in/ligeng-zhu/">LinkedIn</a> -->
                <!--&nbsp;/&nbsp; <a href="https://github.com/lyken17">GitHub</a>-->
                &nbsp;/&nbsp; <a href="https://x.com/hpourv">X</a>  
                <br> <small> Latest update on Dec 13 2025. </small>
              </p>
            </td>
            <td style="padding:2.5%;width:33%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo"
                src="g.jpg">
            </td>
          </tr>
        </table>

     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
            <tr>
              <td>
                <!--<heading>News</heading>
                <ul>
                  <li>
                    Share our recent tiny training work at Westlake university (<a href="assets/slides/tiny_training.pdf">Slides</a>).
                  </li>
                  <li>
                    Our paper on tiny on-device training is highlighted on the <a href="http://web.mit.edu/spotlight/learning-edge/">MIT homepage</a>!
                  </li>
                  <li>
                    Check our <a href="https://tinytraining.mit.edu/">tiny on-device training</a> is accepted to NeurIPS 2022!
                  </li>
                  <li>
                    Awarded for <a href="https://www.qualcomm.com/research/university-relations/innovation-fellowship/2022-north-america">Qualcomm PhD fellowship</a>! Thanks my supervisor and collaboraters!
                  </li>
                  <!-- <li>
                    Check our <a href="https://tinytraining.mit.edu/">recent work</a> that enables a 256kb Micro-Controller to continously adapt to differnet environemnts!
                  </li> -->
                  <!-- <li>
                    Delayed Gradient Averaging is going to appear on <a href="https://neurips.org">NeurIPS 2021</a>.
                    Welcome to our poster session!
                  </li> -->
                  <!-- <li>
                    We are going to present IOS - Inter-Operator Scheduler at <a href="https://mlsys.org">MLSys
                      2021</a>. Welcome to stop by!
                  </li> -->
                  <!-- <li>Co-host <a href="https://hangzhang.org/CVPR2020/">Automated Deep Learning</a> workshop with Amazon Team. 
                    We provide hands on tutorial about Once-for-All, which enables specialization in minutes! 
                    Welcome to play it on <a href="https://colab.research.google.com/github/mit-han-lab/once-for-all/blob/master/tutorial/ofa.ipynb">colab</a>.
                  </li> -->
                  <!-- <li>Two papers are going to appear on NeurIPS. Vancouver, I am back!
                    <ul>
                      <li><a href="https://arxiv.org/abs/1906.08935">
                        Deep Leakage from Gradients
                      </a> on Thu Dec 12th 05 -- 07 PM @ East Exhibition Hall B + C #154
                      </li> 
                      <li><a href="">
                        Distributed Training across the World
                      </a> on Fri Dec 13th 10 AM -- 11 AM @ East Meeting Rooms 11 + 12
                      </li> 
                    </ul>
                  </li>
                  <li>The manuscript of <a href="https://arxiv.org/abs/1904.10616">Design Automation for Efficient Deep Learning Computing</a> is available on arXiv.</li> -->
                </ul>
              </td>
            </tr>

            <td width="100%" valign="middle">
              <!--<heading>Publications</heading><br><br>
              <div>
                <a href="">
                  <papertitle>On-Device Training Under 256KB Memory</papertitle>
                </a>
                <br>
                  Ji Lin* , <strong>Mohammad Hoseinpour*</strong> , Wei-Ming Chen , Wei-Chen Wang , Chuang Gan, Song Han
                <br>
                (* denotes equal contribution, sorted in aplhabetic order)
                <br>
                <em> Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2206.15472">Paper</a>
                &nbsp;/&nbsp;
                <a href="https://tinytraining.mit.edu/">Website</a>
                &nbsp;/&nbsp; 
                <a href="https://tinytraining.mit.edu/assets/on-device-training.pdf">Slides</a>
                &nbsp;/&nbsp; 
                <a href="https://youtu.be/XaDCO8YtmBw">YouTube</a>
                &nbsp;/&nbsp; 
                <a href="https://github.com/mit-han-lab/tiny-training">GitHub</a>
                <!-- &nbsp;/&nbsp;  
                <br>
                <li>
                  Media coverage:
                  <a href="http://web.mit.edu/spotlight/learning-edge/">MIT Homepage</a>
                  &nbsp;/&nbsp; 
                  <a href="https://www.zhihu.com/question/565161486/answer/2779305863">Zhihu</a>
                </li>
              </div>
              <br>
              
              <div>
                <a href="">
                  <papertitle>Enable deep learning on mobile devices: Methods, systems, and applications</papertitle>
                </a>
                <br>
                  Han Cai*, Ji Lin*, Yujun Lin*, Zhijian Liu*, Haotian Tang*, Hanrui Wang*, <strong>Mohammad Hoseinpour</strong>*, Song Han
                <br>
                (* denotes equal contribution, sorted in aplhabetic order)
                <br>
                <em> ACM Transactions on Design Automation of Electronic Systems (TODAES)</em>, 2022
                <br>
                <a href="https://dl.acm.org/doi/pdf/10.1145/3486618">Paper</a>
                <br>
              </div>
              <br>

              <div>
                <a href="">
                  <papertitle>Delayed Gradient Averaging: Tolerate the Communication Latency for Federated Learning
                  </papertitle>
                </a>
                <br>
                <strong>Mohammad Hoseinpour</strong>, Hongzhou Lin, Yao Lu, Yujun Lin, Song Han
                <br>
                <em> Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, 2021
                <br>
                <a href="https://dga.hanlab.ai/assets/neurips21_dga.pdf">Paper</a>
                &nbsp;/&nbsp;
                <a href="http://dga.hanlab.ai/">Webpage</a>
                <!-- &nbsp;/&nbsp;  -->
                <!-- <a href="https://github.com/mit-han-lab/inter-operator-scheduler">Code</a>
                &nbsp;/&nbsp; 
                <a href="https://www.youtube.com/watch?v=cS5I6CYMU2E">YouTube</a>
                &nbsp;/&nbsp; 
                <a href="https://www.bilibili.com/video/BV1w54y187G1">BiliBili</a> 
                <br>
              </div>
              <br>

              <div>
                <a href="">
                  <papertitle>IOS: Inter-Operator Scheduler for CNN Acceleration
                  </papertitle>
                </a>
                <br>
                Yaoyao Ding, <strong>Mohammad Hoseinpour</strong>, Zhihao Jia, Gennady Pekhimenko, Song Han
                <br>
                <em> Conference on Machine Learning and Systems (MLSys)</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2011.01302">Paper</a>
                &nbsp;/&nbsp;
                <a href="http://www.yaoyaoding.com/ios/">Webpage</a>
                &nbsp;/&nbsp;
                <a href="https://github.com/mit-han-lab/inter-operator-scheduler">Code</a>
                &nbsp;/&nbsp;
                <a href="https://www.youtube.com/watch?v=cS5I6CYMU2E">YouTube</a>
                &nbsp;/&nbsp;
                <a href="https://www.bilibili.com/video/BV1w54y187G1">BiliBili</a>
                <br>
              </div>
              <br>

              <div>
                <a href="">
                  <papertitle> TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning </papertitle>
                </a>
                <br>
                Han Cai, Chuang Gan, <strong>Mohammad Hoseinpour</strong>, Song Han
                <br>
                <em> Advances in Neural Information Processing Systems (NeurIPS)</em>, 2020
                <br>
                <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560562.pdf">Paper</a>
                <br>
              </div>
              <br>

              <div>
                <a href="">
                  <papertitle> DataMix: Efficient Privacy-Preserving Edge-Cloud Inference </papertitle>
                </a>
                <br>
                Zhijian Liu, Zhanghao Wu, Chuang Gan, <strong>Mohammad Hoseinpour</strong>, Song Han:
                <br>
                <em> European Conference on Computer Vision (ECCV) </em>, 2020
                <br>
                <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560562.pdf">Paper</a>
                <br>
              </div>
              <br>

              <div>
                <a href="">
                  <papertitle>HAT: Hardware-Aware Transformers for Efficient Neural Machine Translation</papertitle>
                </a>
                <br>
                Hanrui Wang*, Zhanghao Wu*, Zhijian Liu*, Han Cai, <strong>Ligeng Zhu</strong>, and Song Han
                <br>
                <em> Annual Conference of the Association for Computational Linguistics (ACL)</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/2005.14187">Paper</a>
                &nbsp;/&nbsp;
                <a href="https://hat.mit.edu/">Webpage</a>
                &nbsp;/&nbsp;
                <a href="https://github.com/mit-han-lab/hardware-aware-transformers">Code</a>
                &nbsp;/&nbsp;
                <a href="https://www.youtube.com/watch?v=N_tH1jIbqCw">YouTube</a>
                &nbsp;/&nbsp;
                <a href="https://www.bilibili.com/video/BV1mt4y197FL">BiliBili</a>
                <br>
              </div>
              <br>

              <div>
                <a href="">
                  <papertitle>Distributed Training across the World</papertitle>
                </a>
                <br>
                <strong>Ligeng Zhu</strong>,
                Yao Lu,
                Yujun Lin,
                Song Han
                <br>
                <em>Neural Information Processing Systems (NeurIPS) Workshop on Systems for ML (MLSys),</em> 2019
                <br>
                <a href="https://hanlab.mit.edu/projects/dts">Paper</a>
                &nbsp;/&nbsp;
                <a href="assets/posters/19-nips-dts.pdf">Poster</a>
                <br>
                <li>Scale Synchronous SGD across the world, without loss of <font color="red">speed</font> and <font
                    color="red">accuracy</font>!</li>
              </div>
              <br>

              <div>
                <a href="https://arxiv.org/abs/1906.08935">
                  <papertitle>Deep Leakage from Gradients</papertitle>
                </a>
                <br>
                <strong>Ligeng Zhu</strong>,
                Zhijian Liu,
                Song Han
                <br>
                <em>Neural Information Processing Systems (NeurIPS)</em>, 2019
                <br>
                <a href="https://arxiv.org/abs/1906.08935">arXiv</a>
                &nbsp;/&nbsp;
                <a href="assets/posters/19-nips-dlg.pdf">Poster</a>
                &nbsp;/&nbsp;
                <a href="https://gist.github.com/Lyken17/91b81526a8245a028d4f85ccc9191884">Code</a> (implementation in
                <font color="red"><strong>just 20 lines</strong></font>)
              </div>
              <li>
                Media coverage:
                <a href="https://www.zhihu.com/question/345365328/answer/930250128">Zhihu</a>
              </li>
              <br>

              <div>
                <a href="https://ieeexplore.ieee.org/document/8897011">
                  <papertitle>AutoML for Architecting Efficient and Specialized Neural Networks</papertitle>
                </a><br>
                Han Cai*,
                Ji Lin*,
                Zhijian Liu*,
                Yujun Lin*,
                Kuan Wang*,
                Tianzhe Wang*,
                <strong>Ligeng Zhu*</strong>,
                Song Han
                <br>
                (* denotes equal contribution, sorted in aplhabetic order)
                <br>
                <em>IEEE International Symposium on Microarchitecture (Micro)</em>, 2019
                <br>
                <a href="https://arxiv.org/abs/1904.10616">arXiv</a> &nbsp;/&nbsp;
                <a href="https://ieeexplore.ieee.org/document/8897011">Paper</a> &nbsp;/&nbsp;
                <a href="https://www.dropbox.com/s/qipuwtjktnkhhr0/CVPR%2719%20Song%20Han.pdf?dl=0">Slides</a>
              </div><br>

              <div>
                <a href="https://arxiv.org/abs/1812.00332">
                  <papertitle>ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware.</papertitle>
                </a>
                <br>
                Han Cai,
                <strong>Ligeng Zhu</strong>,
                Song Han
                <br>

                <em>International Conference on Learning Representations (ICLR) </em>, 2019 <font color="red">
                  <strong>(378 citations)</strong>
                </font>
                <br>
                <a href="https://arxiv.org/abs/1812.00332">arXiv</a> &nbsp;/&nbsp;
                <a href="https://hanlab.mit.edu/projects/proxylessNAS">Project Page</a> &nbsp;/&nbsp;
                <a href="https://github.com/MIT-HAN-LAB/ProxylessNAS">GitHub</a>
                <font color="red">(1.1k stars)</font>
                <font color="red">(integrated into <a
                    href="https://pytorch.org/hub/pytorch_vision_proxylessnas/">PyTorch Hub</a>)</font>
                &nbsp;/&nbsp; <a href="assets/posters/19-iclr-poster.pdf">Poster</a>
                <br>
                <li>Media coverage:
                  <a href="http://news.mit.edu/2019/convolutional-neural-network-automation-0321">MIT News</a>,
                  <a href="https://spectrum.ieee.org/tech-talk/computing/networks/using-ai-to-make-better-ai">IEEE
                    Spectrum</a>,
                  <a href="https://www.zhihu.com/question/296404213/answer/547163236">Zhihu</a>,
                  <a href="https://www.jiqizhixin.com/articles/2018-12-07-8">机器之心</a>
                </li>
              </div><br>

              <div>
                <a href="https://arxiv.org/abs/1801.05895">
                  <papertitle>Sparsely Aggregated Convolutional Networks</papertitle>
                </a><br>
                <strong>Ligeng Zhu</strong>,
                Ruizhi Deng,
                Michael Maire,
                Zhiwei Deng,
                Greg Mori,
                Ping Tan
                <br>
                <em>European Conference on Computer Vision (ECCV)</em>, 2018
                <br>
                <a href="https://arxiv.org/abs/1801.05895">arXiv</a>
                &nbsp;/&nbsp; <a href="https://github.com/lyken17/sparsenet">Code</a>
                &nbsp;/&nbsp; <a href="assets/posters/18-eccv-poster.pdf">Poster</a>
              </div><br>

              <div>
                <a href="https://ieeexplore.ieee.org/document/8581453">
                  <papertitle>Small Object Sensitive Segmentation of Urban Street Scene With Spatial Adjacency Between
                    Object Classes.</papertitle>
                </a>
                <br>
                Dazhou Guo*,
                <strong>Ligeng Zhu*</strong>,
                Yuhang Lu,
                Hongkai Yu,
                Song Wang
                <br>
                <em>IEEE Transactions on Image Processing (TIP)</em>, 2018
                <br>
                <a href="https://ieeexplore.ieee.org/document/8581453">Paper</a>
              </div><br>

              <div>
                <a href="https://www2.cs.sfu.ca/~funt/Funt_Zhu_DoesColourMatter_CIC26_2018.pdf">
                  <papertitle>Does Colour Really Matter? Evaluation via Object Classification.</papertitle>
                </a>
                <br>
                Brian Funt,
                <strong>Ligeng Zhu</strong>
                <br>
                <em> Color and Imaging Conference (CIC)</em>, 2018
                <br>
                <a href="https://www2.cs.sfu.ca/~funt/Funt_Zhu_DoesColourMatter_CIC26_2018.pdf">Paper</a>
                &nbsp;/&nbsp; <a href="assets/posters/18-cic-poster.pdf">Poster</a>
              </div><br>

              <div>
                <a href="https://doi.org/10.2352/ISSN.2470-1173.2018.14.HVEI-541">
                  <papertitle>Colorizing Color Images.</papertitle>
                </a>
                <br>
                <strong>Ligeng Zhu</strong>,
                Brian Funt
                <br>
                <em>Human Vision and Electronic Imaging (HEVI)</em>, 2018
                <br>
                <a href="https://doi.org/10.2352/ISSN.2470-1173.2018.14.HVEI-541">Paper</a>
                &nbsp;/&nbsp; <a href="https://github.com/Lyken17/Colorize-Color-Images">Code</a>
                &nbsp;/&nbsp; <a href="assets/posters/18-hvei-poster.pdf">Poster</a>
              </div><br>

              <div>
                <a href="https://arxiv.org/abs/1607.01437">
                  <papertitle>Attribute Recognition from Adaptive Parts.</papertitle>
                </a>
                <br>
                Luwei Yang,
                <strong>Ligeng Zhu</strong>,
                Yichen Wei, Shuang Liang, Ping Tan.
                <br>
                <em>British Machine Vision Conference (BMVC)</em>, 2016
                <br>
                <a href="https://arxiv.org/abs/1607.01437">arXiv</a>
                &nbsp;/&nbsp; <a href="assets/posters/16-bmvc-poster.pdf">Poster</a>
              </div><br>
            </td>

            <tr>
              <td>
                <heading>Talks & Presentations</heading>
                <ul>
                  <!-- <li>[03/2020] Scalable and Secure Federated Learning (<a href="assets/slides/2020-03-FL.pdf">Slides</a>)
                      <ul>
                        @ UCSD SVCL, Xilinx, Dawnlight, NYU System Group
                      </ul>
                    </li>
                    <li>[12/2019] Distributed Training across the World 
                      @ MIT CSAIL Fast ML  (<a href="assets/slides/19-CSAIL-Fast-ML.pdf">Slides</a>) 
                    </li> 
                  <li>[08/2019] AutoML for Efficient Neural Architecture Design (<a
                      href="https://static.sched.com/hosted_files/openpowerna19/43/proxyless%40summit.pdf">Slides</a>)
                    <ul>@ OpenPower Summit, Polarr Tech</ul>
                  </li>
                  <li>[08/2019] Scalable and Secure Machine Learning for Edge Devices @ Qualcomm </li>
                  <li>[05/2019] Neural Architecture Designs @ UIUC IFP Group (<a
                      href="assets/slides/ligeng's presentation@UIUC IFP.pdf">Slides</a>) </li>
                  <li>[12/2018] Proxylessly Specialize CNN for Hardware @ IBM-MIT Watson Events (<a
                      href="assets/posters/18-ibm_proxyless.pdf">Poster</a>) </li>
                  <li>[01/2018] Sparsely Aggregated Convolutional Networks (<a
                      href="assets/posters/18-SparseNet@ver1.pdf">Slides</a>)
                    <ul> @ UBC Vision Group, Deephi Tech, Sensetime Inc</ul>
                  </li>
                  <li>[11/2017] Invited lectures about deep learning
                    (<a href="https://bit.ly/37UTJOo">Lecture1</a>,
                    <a href="https://bit.ly/34HWlxa">Lecture2</a>)
                    <ul>@ SFU Computer Vision Course (CMPT-412), ZJU Programming Group</ul>
                  </li>
                </ul>
              </td>
            </tr>

            <tr>
              <td>
                <heading>Open-source Projects (Selected)</heading>
                <p>
                  My life (both academic and daily) is greatly powered by open source projects. To thank their selfless
                  effort, I embrace open source as much as possible. Please refer to <a
                    href="https://github.com/Lyken17">my github</a> for a complete list of projects.
                </p>

                <table style="width:100%" valign="middle">
                  <tr>
                    <th>
                      <div>
                        <a href="https://github.com/Lyken17/pytorch-OpCounter">
                          <papertitle>PyTorch-OpCounter</papertitle>
                        </a>
                        <br>
                        <a class="github-button" href="https://github.com/lyken17/pytorch-OpCounter"
                          data-icon="octicon-star" data-show-count="true"
                          aria-label="Star lyken17/pytorch-OpCounter on GitHub">Star</a>
                        <a class="github-button" href="https://github.com/lyken17/pytorch-OpCounter/fork"
                          data-icon="octicon-repo-forked" data-show-count="true"
                          aria-label="Fork lyken17/pytorch-OpCounter on GitHub">Fork</a>
                        <br>
                        <span style="font-weight:normal">Count the MACs / FLOPs of your PyTorch model.</span>
                        <br>
                        <span style="font-weight:normal">Avaliable through PyPi:
                          <code>pip install thop</code>
                        </span>
                      </div>
                    </th>
                    <th>
                      <div>
                        <a href="https://github.com/mit-han-lab/ProxylessNAS">
                          <papertitle>ProxylessNAS</papertitle>
                        </a>
                        <br>
                        <a class="github-button" href="https://github.com/mit-han-lab/ProxylessNAS"
                          data-icon="octicon-star" data-show-count="true"
                          aria-label="Star lyken17/pytorch-OpCounter on GitHub">Star</a>
                        <a class="github-button" href="https://github.com/mit-han-lab/ProxylessNAS/fork"
                          data-icon="octicon-repo-forked" data-show-count="true"
                          aria-label="Fork lyken17/pytorch-OpCounter on GitHub">Fork</a>
                        <br>
                        <span style="font-weight:normal">Directly and efficiently search neural network
                          architectures.</span>
                        <br>
                        <span style="font-weight:normal">Integrated into <a
                            href="https://pytorch.org/hub/pytorch_vision_proxylessnas/">PyTorch Hubs</a>!
                        </span>
                      </div>
                    </th>
                  </tr>
                  <tr>
                    <th>
                      <div>
                        <a href="https://github.com/Lyken17/pytorch-memonger">
                          <papertitle>PyTorch-Memonger</papertitle>
                        </a>
                        <br>
                        <a class="github-button" href="https://github.com/Lyken17/pytorch-memonger"
                          data-icon="octicon-star" data-show-count="true"
                          aria-label="Star lyken17/pytorch-OpCounter on GitHub">Star</a>
                        <a class="github-button" href="https://github.com/Lyken17/pytorch-memonger/fork"
                          data-icon="octicon-repo-forked" data-show-count="true"
                          aria-label="Fork lyken17/pytorch-OpCounter on GitHub">Fork</a>
                        <br>
                        <span style="font-weight:normal">Sublinear memory optimization for deep learning.</span>
                        <br>
                      </div>
                    </th>
                    <th>
                      <div>
                        <a href="https://github.com/Lyken17/Efficient-PyTorch">
                          <papertitle>Efficient-PyTorch</papertitle>
                        </a>
                        <br>
                        <a class="github-button" href="https://github.com/Lyken17/Efficient-PyTorch"
                          data-icon="octicon-star" data-show-count="true"
                          aria-label="Star lyken17/pytorch-OpCounter on GitHub">Star</a>
                        <a class="github-button" href="https://github.com/Lyken17/Efficient-PyTorch/fork"
                          data-icon="octicon-repo-forked" data-show-count="true"
                          aria-label="Fork lyken17/pytorch-OpCounter on GitHub">Fork</a>
                        <br>
                        <span style="font-weight:normal">My best practice of training large dataset using
                          PyTorch.</span>
                        <br>
                      </div>
                    </th>
                  </tr>
                </table>
              </td>
            </tr>

            <tr>
              <td>
                <heading>Services</heading>
                <p>
                  Review papers for:
                  <li>
                    NeurIPS 22 / CVPR 22 / NeurIPS 21 / ICCV 21 / ICML 21 / ACL 21 / NeurIPS 20 / CVPR 20 / AAAI 20 / NeurIPS 19 / ICCV 19 / CVPR 19
                  </li>
                  <li>
                    T-PAMI / IEEE Micro
                  </li>-->

                </p>
              </td>
            </tr>
          </tbody>

        </table>
        <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
             <!-- <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's
                  website</a>.
                Style adapted from <a style="font-size:small;" href="http://zhijianliu.com">Zhijian Liu's website</a>.
                </a>
              </p>-->
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
  <!-- Place this tag in your head or just before your close body tag. -->
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-129647900-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-129647900-1');
  </script>
</body>

</html>





















